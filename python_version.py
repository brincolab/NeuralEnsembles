# -*- coding: utf-8 -*-
"""data_ruben_version.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kC40pTSj8eSs4_UVDlW5_dZxKJtbqzvG

# **Example of ensemble detection from a synthetic raster.**
"""

pip install spikelib

pip install spikeextractors

import numpy as np
import scipy.stats
import matplotlib.pyplot as plt
from math import floor
from scipy.stats import t,linregress
from numpy import sum as arraysum
from numpy import sqrt
from scipy.special import erfinv
from scipy.spatial.distance import cdist, pdist, squareform,correlation
from sklearn.decomposition import PCA
import spikelib
import h5py
from google.colab import drive
import h5py
import numpy as np
import matplotlib.pyplot as plt
from spikelib import spiketools as spkt
import pandas as pd
import numpy as np

drive.mount('/content/drive')

##read data
from scipy import io
# Load the mat file
filepath ='/content/drive/MyDrive/codigo_python/chirp_319.mat'
data = io.loadmat(filepath)
raster = data['AD']
raster1 = raster[:,66000:96000]

x_coords = np.argwhere(raster1==1)[:,0]
y_coords = np.argwhere(raster1==1)[:,1]
plt.figure(figsize=(20, 8))
plt.plot(y_coords.flatten(),x_coords.flatten(), 'k|')
plt.show()

def paraSetv2(dist, percNeigh):
# using the modified version of Yger et al 2016, related to spike sorting.
# Reference paper: Herzog et al. 2020 "Scalable and accurate automated method
# for neuronal ensemble detection in spiking neural networks"
# https://www.biorxiv.org/content/10.1101/2020.10.12.335901v1
# Rubén Herzog October 2020
    global rho
    NE = np.shape(dist)[0] # NE is assigned the number of rows in the `dist` array
    dc = int(round(percNeigh * NE))  # percentage of nearest neighbors, S in the cited paper.
    dist_sorted = np.sort(dist).T # sorted in ascending order along the first dimension (rows)
    rho = 1/ np.mean(dist_sorted[1:dc+1,:], axis=0)  # Yger 2016
    np.count_nonzero(np.isnan(rho))
    return rho, dc

def mat_tri_inf(dist, rho):
    delta1 = np.zeros((len(rho),len(rho)))
    for i in range(len(rho)):
          delta1[i,:i+1] = 1
    delta1 =np.array(delta1)

    return delta1

def delta_from_dist_mat(dist, rho):
    global delta
    # sort rho in descending order and get the indices of the sorted array
    ordRho =np.argsort(-rho)
    # create a matrix where the element (i,j) is 1 if rho(ordRho[i]) >= rho(ordRho[j])
    gtmat = mat_tri_inf(dist, rho)
    # set the distances of lower density points to 0
    indices = np.ix_(ordRho, ordRho)
    dist = dist[indices]
    seldist = gtmat*dist
    # set the lower diagonal to the greater density values
    seldist = np.tril(seldist, k=-1)
    # set 0 distances to infinity to avoid getting them as minimal values
    seldist[seldist == 0.0] = np.inf
    indices1 = np.argsort(ordRho)
    sorted_seldist = seldist[indices1, :]
    sorted_seldist = sorted_seldist[:, indices1]
    # take the minimal distance to any other point with higher density
    delta = np.min(sorted_seldist, axis=1)
    # set delta of the highest density point to the maximum non-infinite delta value
    delta[rho == max(rho)] = max(delta[~np.isinf(delta)])
    # set infinite delta values to 0
    delta[np.isinf(delta)] = 0
    delta = np.array(delta.T)

    return delta

import numpy as np
from scipy.stats import t
from numpy import sum as arraysum
from numpy import sqrt
from scipy.stats import linregress
import matplotlib.pyplot as plt
from scipy.special import erfinv

def cluster_dist(delta, rho, pb):
    """
    delta: the minimum distance to a point with higher density
    rho: the distance from the closest neighbours
    pb: confidence level
    """
    global nzrho, nzdelta, predbounds
    mindelta = 10 ** -4  # min delta to be considered, improves the fit
    nzind = np.where((delta > mindelta) & (rho > 0) & (~np.isinf(rho)))  # uses only points with delta>mindelta and rho>0
    nzdelta = delta[nzind].astype(float)  # use only point with nzind condition in delta and with type float
    nzrho = rho[nzind].astype(float)  # use only point with nzind condition in rho and with type float

    x = np.log(nzrho)  # Vector associated to y
    y = np.log(nzdelta)  # Vector data
    b1, b0, r_value, p_value, std_err = linregress(x.T, y.T)  # linear regression
    y_pred = b0 + b1 * x  # vector of predicted value for x
    # Fit a polynomial of degree 1 to y_pred
    #poly_coeffs = np.polyfit(x, y,deg=1)
    #y_pred_fit = np.polyval(poly_coeffs, x)
    #print(y_pred_fit)
    upper_bounds = []  # initialization list
    # loop to implement the additional part of interval
    for i in range(len(x)):
        x_in = x[i]
        y_out = y[i]
        y_pred_out = y_pred[i]

        sum_errs = arraysum((y - y_pred) ** 2)  # calculate the sum of the errors in square
        stdev = sqrt(1 / (len(y) - 2) * sum_errs)  # standard deviation
        z = sqrt(2) * erfinv(pb / 100)  # confidence coefficient
        interval = z * stdev  # Calculate the margin of error.
        upper = y_pred_out + interval  # the upper part of the interval
        # downer = y_pred_out - interval #
        upper_bounds.append(upper)  # ajouter a la liste
    upper_bounds = np.array(upper_bounds)  # list to matrix

    # extract cluster
    auxid = nzdelta > np.exp(upper_bounds)
    predbounds = np.hstack((np.array(nzrho)[:, np.newaxis], np.exp(upper_bounds)[:, np.newaxis]))
    centid = np.where(auxid)[0]  # arg of the cluster
    numClust = len(centid)  # number of clusters
    centInd = np.zeros(len(rho.T))  # numerate the cluster
    centInd[centid] = np.arange(numClust) + 1
    return numClust, centInd, predbounds

def find_core_cells_by_correlation(raster, ens_raster, nsur, p):
    """
    Detectes the core neurons of a given raster. A core neuron is defined as
    a neuron whose correlation with an ensemble is bigger than the
    correlation by chance (random spike sequence with the same firing rate).

    Inputs:
        raster: numpy array, shape (N, T), where raster[n, t]=1 if neuron 'n'
                fired at time 't' and 0 otherwise.
        ens_raster: numpy array, shape (nens, Tens), where ens_raster[nen, t]=1 if
                    ensemble nen is active at time t and 0 otherwise.
        nsur: int, the number of artificial data to generate chance level
        p: float, the percentile to use as a threshold of the random distribution.

    Outputs:
        neuronid: numpy array, shape (N,), where each entry is either 0 or 1,
                  where 0 is a non-core neuron and 1 is a core neuron.
        idthr: numpy array, shape (N,), the threshold used to classify core neurons.
        ens_cel_corr: numpy array, shape (N, nens), the correlation between each cell and ensemble.
        sur_cel_cor: numpy array, shape (N, nens, nsur), the correlation between each cell and
                     artificially generated ensembles.
    """
    
    np.set_printoptions(precision=8)
    global neuronid, idthr, ens_cel_corr, sur_cel_cor
    N, T = np.shape(raster)
    nens, Tens = np.shape(ens_raster)
    if T == Tens and T == N:
        raise ValueError('Raster and ensemble-raster leng5th must be equal')

    ens_cel_corr = 1 - cdist(raster, ens_raster, metric='correlation')
    sur_cel_cor = np.zeros((N,nens,nsur))
    for s in range(nsur):
      sur_ens_seq = np.ones(np.shape(ens_raster))
      for i in range(ens_raster.shape[0]):
          sur_ens_seq[i, :] = np.random.permutation(ens_raster[i, :])
      sur_cel_cor[:,:,s] = 1-cdist(raster,sur_ens_seq,metric='correlation')

    idthr = np.percentile(sur_cel_cor,p, axis = 2, interpolation='midpoint')
    neuronid = ens_cel_corr > idthr
    return neuronid, idthr, ens_cel_corr, sur_cel_cor

def filter_ens_by_inner_corr(raster, core_cells, sdfact):
    C_cells = np.corrcoef(raster)
    C_cells = np.triu(C_cells, k=1)
    C_cells[C_cells==0] = np.nan
    #core_cells_sum = np.where(np.sum(core_cells, axis=1)==0)
    core_cells_sum = np.sum(core_cells, axis=1)
    noncore_idx = np.where(core_cells_sum == 0)[0]

    noncore_corr = np.nanmean(np.nanmean(C_cells[noncore_idx[:, np.newaxis], noncore_idx],axis = 0))
    noncore_std = np.nanstd(np.nanstd(C_cells[noncore_idx[:, np.newaxis], noncore_idx], axis=0,ddof=1),ddof=1)
    print(noncore_std)
    print(noncore_corr)
    if np.isnan(noncore_corr):
        noncore_corr = np.nanmean(np.nanmean(C_cells))
        noncore_std = np.nanstd(np.nanstd(C_cells,ddof=1),ddof=1)

    core_cells = core_cells.astype('int')
    ens_corr = [np.nanmean(np.nanmean(C_cells[np.ix_(np.argwhere(core_cells[:, i] == 1)[:, 0], np.argwhere(core_cells[:, i] == 1)[:, 0])],axis = 0)) for i in range(core_cells.shape[1])]
    ens_corr = np.array(ens_corr)
    corr_thr = noncore_corr + sdfact*noncore_std
    selection = (ens_corr > corr_thr)

    return ens_corr, corr_thr, selection

def raster2ens_by_density(raster, pars):
    # 1.- parameters definitions
    if 'npcs' not in pars or pars['npcs'] is None:
        pars['npcs'] = 6
    if 'dc' not in pars or pars['dc'] is None:
        pars['dc'] = 0.02
    if 'minspk' not in pars or pars['minspk'] is None:
        pars['minspk'] = 3
    if 'minsize' not in pars or pars['minsize'] is None:
        pars['minsize'] = 2
    if 'cent_thr' not in pars or pars['cent_thr'] is None:
        pars['cent_thr'] = 95
    if 'nsur' not in pars or pars['nsur'] is None:
        pars['nsur'] = 100
    if 'prct' not in pars or pars['prct'] is None:
        pars['prct'] = 99.9
    if 'inner_corr' not in pars or pars['inner_corr'] is None:
        pars['inner_corr'] = 0
    global ras
    # 2.- Selection of bins
    N, T = np.shape(raster)
    selbins = np.sum(raster, axis=0) > pars['minspk']
    raster=np.array(raster)
    ras = raster[:,selbins]*1

    # 3 pca and distance matrix
    global bincor, pcs
    pca = PCA()
    pcs = pca.fit_transform(ras.T)
    pcs = pcs[:, :pars['npcs']]
    bincor = cdist(pcs,pcs,'euclidean')
    bincor = np.round(bincor, 4)
    print('pcs',np.shape(pcs))

    # 4.- rho and delta computation
    global labels
    rho = paraSetv2(bincor, pars['dc'])[0]
    delta = delta_from_dist_mat(bincor, rho)
    Nens, cents, predbounds = cluster_dist(delta,rho,pars['cent_thr'])

    if Nens == 1:
        labels = np.ones(len(delta), dtype=int)
    else:
        dist2cent = bincor[cents > 0, :]
        labels = np.argmin(dist2cent, axis=0)
    resulta = []
    i = 0
    for j in range(len(selbins)):
        if selbins[j] == 1:
            resulta.append(labels[i])
            i += 1
        else:
            resulta.append(0)

    # 5.- ensemble raster
    ensmat_out = np.zeros((Nens,T))
    for i in range(len(resulta)):
      ensmat_out[resulta[i],i] = 1

    # 6.- core-cells computation
    core_cells,_, ens_cel_corr, sur_cel_cor = find_core_cells_by_correlation(raster, ensmat_out, pars['nsur'], pars['prct'])
    id_sel_core = np.sum(core_cells, axis=0) > pars['minsize']

    # 7.- filtering core cells
    ens_corr, corr_thr, corr_selection = filter_ens_by_inner_corr(raster, core_cells, pars['inner_corr'])
    print('ICIREFAAR',corr_selection)
    final_sel_ens = corr_selection & id_sel_core

    # 8.- final ensemble outputs
    sel_ensmat_out = ensmat_out[final_sel_ens, :] # filtering by magnitude & inner cell correlation
    sel_core_cells = core_cells[:, final_sel_ens]
    return sel_ensmat_out, sel_core_cells

import matplotlib.lines as mlines
import plotly.graph_objects as go

pop_activity = np.sum(raster1, axis=0)
plt.hist(pop_activity)

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
N,T = np.shape(raster1)
tt = np.arange(T)
#fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(20, 10))
nn=np.arange(N)

def save_ensmat_detcore(raster, dc_values, cent_thr_values,minspk_values):
    results = {}

    for dc in dc_values:
        for minspk in minspk_values:
                for cent_thr in cent_thr_values:
                    pars = {
                        'dc': dc,
                        'npcs': 6,
                        'minspk': minspk,
                        'nsur': 100,
                        'prct': 99.9,
                        'cent_thr': cent_thr,
                        'inner_corr': 0,
                        'minsize': 3,
                    }
                    print('DC',dc,'minspk',minspk,'cent_thr',cent_thr)
                    ensmat_out, det_core_cells = raster2ens_by_density(raster1, pars)

                    fig = plt.figure(figsize=(20,15))
                    grid = plt.GridSpec(3, 3, wspace=0.2, hspace=0.2)
                    # Create the subplots
                    # fig, axes = plt.subplots(nrows=3, ncols=3,sharex='col', sharey='row')


                    ax1 = plt.subplot(grid[0, 0],projection='3d')
                    ax2 = plt.subplot(grid[0, 1],projection='3d')
                    ax3 = plt.subplot(grid[0, 2])
                    ax4 = plt.subplot(grid[1, :]);
                    ax5 = plt.subplot(grid[2, 0]);
                    ax6 = plt.subplot(grid[2, 2]);

                    # First subplot: scatter plot without cluster colors
                    ax1.scatter(pcs[:, 0], pcs[:, 1], pcs[:, 2],s=5)
                    ax1.set_xlabel('PC1')
                    ax1.set_ylabel('PC2')

                    # Second subplot: scatter plot with cluster colors
                    cluster_colors = {e: f"C{e}" for e in range(ensmat_out.shape[0]+1)}
                    #ax2 = fig.add_subplot(332, projection='3d')
                    for e in range(ensmat_out.shape[0]+1):
                        ax2.scatter(pcs[labels==e, 0], pcs[labels==e, 1], pcs[labels==e, 2], c=cluster_colors[e],s=5)
                    ax2.set_xlabel('PC1')
                    ax2.set_ylabel('PC2')
                    legend_elements = [mlines.Line2D([], [], marker='o', color=cluster_colors[e], label=f'Cluster {e}') for e in cluster_colors]
                    ax2.legend(handles=legend_elements)

                    # Third subplot: line plots
                    #ax3 = fig.add_subplot(339)
                    ax3.plot(nzrho, predbounds[:, 1], '.')
                    ax3.plot(nzrho, nzdelta, '.')
                    ax3.set_xlabel('nzrho')
                    ax3.set_ylabel('predbounds/nzdelta')

                    # Fourth subplot: ensemble activation plot
                    tt = np.arange(np.shape(ensmat_out)[1])

                    # Créez une palette de couleurs avec suffisamment de couleurs pour chaque ensemble
                    palette = plt.cm.get_cmap('rainbow', ensmat_out.shape[0])

                    # Remplacez la boucle existante par ceci
                    for e in range(ensmat_out.shape[0]):
                        color = palette(e)  # Sélectionnez une couleur unique pour chaque ensemble
                        ax4.plot(tt[ensmat_out[e, :] > 0], ensmat_out[e, ensmat_out[e, :] > 0] * e, 'o', color=color, label=f'Ensemble {e}')
                        ax4.axhline(y=e, color=color, linestyle='--')

                    # Ajoutez une légende pour identifier chaque ensemble
                    ax4.legend()

                    # Le reste du code reste inchangé
                    interval = 3000
                    num_intervals = int(tt[-1] / interval)
                    for i in range(num_intervals + 2):
                        if i % 2 == 0:
                            ax4.axvspan(i * interval, (i + 1) * interval, facecolor='black', alpha=0.2)
                        else:
                            ax4.axvspan(i * interval, (i + 1) * interval, facecolor='white', alpha=0.2)
                    ax4.set_xlabel('Time')
                    ax4.set_ylabel('Ensemble ID')
                    ax4.set_yticks(np.arange(ensmat_out.shape[0]))
                    ax4.set_ylim([-1, ensmat_out.shape[0] + 0.5])

                    #ax4 = fig.add_subplot(334)
                   # for e in range(ensmat_out.shape[0]):
                   #     ax4.plot(tt[ensmat_out[e, :] > 0], ensmat_out[e, ensmat_out[e, :] > 0] * e, 'bo')

                  #  interval = 3000
                   # num_intervals = int(tt[-1] / interval)
                   # for i in range(num_intervals+2):
                   #     if i % 2 == 0:
                   #         ax4.axvspan(i * interval, (i + 1) * interval, facecolor='black', alpha=0.2)
                   #     else:
                   #         ax4.axvspan(i * interval, (i + 1) * interval, facecolor='white', alpha=0.2)
                   # ax4.set_xlabel('Time')
                    #ax4.set_ylabel('Ensemble ID')
                    #ax4.set_yticks(np.arange(ensmat_out.shape[0]))
                    #ax4.set_ylim([-1, ensmat_out.shape[0]+0.5])

                    ##corr cell mean
                    sum_cluster=[]
                    for i in range(np.shape(det_core_cells)[1]):
                        sum_cluster.append(np.sum(det_core_cells[:,i])/len(det_core_cells))
                    mean_core_cells = np.mean(sum_cluster)

                    # Fifth subplot: Core-Cells mean
                    #ax5 = fig.add_subplot(337)
                    ax5.axhline(y=mean_core_cells, color='r', linestyle='--')
                    ax5.bar(range(len(sum_cluster)), sum_cluster)
                    ax5.set_xlabel('Cluster')
                    ax5.set_ylabel('Core-Cells mean')
                    ax5.set_title('Sum of Clusters')

                    # Sixth subplot: enscells_in
                    #ax6 = fig.add_subplot(338)
                    ax6.imshow(det_core_cells.T, aspect='auto')
                    ax6.set_xlabel('Ensembles')
                    ax6.set_ylabel('Cells')
                    ax6.set_title('Enscells_in')

                    # Adjust the layout and display the plot
                    fig.tight_layout()
                    plt.show()

                    key = f'dc={dc}cent_thr={cent_thr}_minspk={minspk}'
                    results[key] = {'ensmat_out_off': ensmat_out, 'det_core_cells_off': det_core_cells}

    return results

# Example usage
dc_values = [0.015]
cent_thr_values = [85]
minspk_values = [6]

results = save_ensmat_detcore(raster, dc_values, cent_thr_values,minspk_values)
# Accessing the results
for key, value in results.items():
    print(key)
    print('ensmat_out_off:', value['ensmat_out_off'])
    print('det_core_cells_off:', value['det_core_cells_off'])
    print('---')

#ax6 = fig.add_subplot(338)
                    ax6.imshow(det_core_cells.T, aspect='auto')
                    ax6.set_xlabel('Ensembles')
                    ax6.set_ylabel('Cells')
                    ax6.set_title('Enscells_in')

                    # Adjust the layout and display the plot
                    fig.tight_layout()
                    plt.show()

                    fig = go.Figure(data=[go.Scatter3d(x=pcs[:, 0], y=pcs[:, 1], z=pcs[:, 2], mode='markers',
                                                      marker=dict(size=1))])
                    fig.update_layout(scene=dict(xaxis_title='PC1', yaxis_title='PC2', zaxis_title='PC3'))
                    fig.show()

                    key = f'dc={dc}_inner_corr={inner_corr}_npcs={npcs}'
                    results[key] = {'ensmat_out_off': ensmat_out, 'det_core_cells_off': det_core_cells}
